{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project_image_data_augmentation-adamiaonr.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamiaonr/cveml/blob/main/projects/scripts/notebooks/project_image_data_augmentation_adamiaonr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32-zMt7tZr3R"
      },
      "source": [
        "# Project: Image Data Augmentation\n",
        "\n",
        "[![Open In Colab <](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ShawnHymel/computer-vision-with-embedded-machine-learning/blob/master/2.3.5%20-%20Project%20-%20Data%20Augmentation/project_image_data_augmentation.ipynb)\n",
        "\n",
        "This is an example for creating an augmented dataset. It will transform input images to create a series of augmented samples that are saved in a new output directory.\n",
        "\n",
        "Create a folder named \"dataset\" in the /content directory and upload your images there. The images should be divided into their respective classes, where each class has its own folder with the name of the class. For example:\n",
        "\n",
        "<pre>\n",
        "/content\n",
        "    |- dataset\n",
        "        |- background\n",
        "        |- capacitor\n",
        "        |- diode\n",
        "        |- led\n",
        "        |- resistor\n",
        "</pre>\n",
        "\n",
        "The original images along with their transforms will be saved in the output directory. Each output file will be the original filename appended with \"_{num}\" where {num} is some incrementing value based on the total number of transforms performed per image.\n",
        "\n",
        "For example, if you have a file named \"0.png\" in /content/dataset/resistor, it will become \"0_0.png\" in /content/output/resistor. The first transform will be \"0_1.png\", the second transform will be \"0_2.png\" and so on.\n",
        "\n",
        "Run each of the cells paying attention to their contents and output. Fill out the necessary parts of the functions where you find the following comment:\n",
        "\n",
        "```\n",
        "# >>> ENTER YOUR CODE HERE <<<\n",
        "```\n",
        "\n",
        "Author: EdgeImpulse, Inc.<br>\n",
        "Date: August 3, 2021<br>\n",
        "Modified by: adamiaonr@gmail.com<br>\n",
        "Last modified: January 2, 2022<br>\n",
        "License: [Apache-2.0](apache.org/licenses/LICENSE-2.0)<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RTimcB-ZoIT"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "import skimage.transform\n",
        "import skimage.util"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zJCNZmEaCCN"
      },
      "source": [
        "### Settings\n",
        "\n",
        "# Location of dataset and output folder\n",
        "DATASET_PATH = \"/content/dataset\"\n",
        "OUT_PATH = \"/content/output\"\n",
        "OUT_ZIP = \"augmented_dataset_v2_0_6.zip\"\n",
        "\n",
        "# File format to use for new dataset\n",
        "IMG_EXT = \".png\"\n",
        "\n",
        "# You are welcome to change the seed to get different augmentation effects\n",
        "SEED = 42\n",
        "random.seed(SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "siLr8t4-qR9K"
      },
      "source": [
        "### Create output directory\n",
        "!rm -rf \"{OUT_PATH}\"\n",
        "!rm -rf \"{OUT_ZIP}\"\n",
        "\n",
        "try:\n",
        "  os.makedirs(OUT_PATH)\n",
        "except FileExistsError:\n",
        "  print(\"WARNING: Output directory already exists. Check to make sure it is empty.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAZYWLFeB9vR"
      },
      "source": [
        "## Transform Functions\n",
        "\n",
        "Create one or more functions that transform an input image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxh8f4JXgnTa"
      },
      "source": [
        "### Example: Function to create 3 new flipped images of the input\n",
        "def create_flipped(img):\n",
        "\n",
        "  # Create a list of flipped images\n",
        "  flipped = []\n",
        "  flipped.append(np.fliplr(img))\n",
        "  flipped.append(np.flipud(img))\n",
        "  flipped.append(np.flipud(np.fliplr(img)))\n",
        "\n",
        "  return flipped\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAIqA5xdtt_6"
      },
      "source": [
        "# >>> ENTER YOUR CODE HERE <<<\n",
        "# Create one or more functions that create transforms of your images\n",
        "\n",
        "# rotation : rotates image with the provided angles ([-135, -45, 45, 135] by default)\n",
        "def create_rotated(img, angles = [-135, -45, 45, 135], flip = False):\n",
        "  rotated = []\n",
        "  for angle in angles:\n",
        "    img_rotated = skimage.transform.rotate(img, angle = angle, mode='edge', preserve_range=True).astype(np.uint8)\n",
        "    rotated.append(img_rotated)\n",
        "\n",
        "    if flip:\n",
        "      rotated.append(np.fliplr(img_rotated))\n",
        "\n",
        "  return rotated\n",
        "\n",
        "# translation : creates a list of translations of a source image along {x, y} axis, in the form {x * (1 + a), y * (1 + b)}\n",
        "# the (a, b) coefficients to apply are passed as a list.\n",
        "def create_translated(img, translation_coef = [0.0, .25, .5, .75], flip = False):\n",
        "  translated = []\n",
        "\n",
        "  height = img.shape[0]\n",
        "  width = img.shape[1]\n",
        "\n",
        "  for c in translation_coef:\n",
        "    tr_x = [ round(( random.random() * k ) * ( width / 2 ))  for k in [ c, c, -c, -c ] ]\n",
        "    for c in translation_coef:\n",
        "      tr_y = [ round(( random.random() * k ) * ( height / 2 )) for k in [ c, c, -c, -c ] ]\n",
        "      for i, p in enumerate([(x, y) for x, y in zip(tr_x, tr_y)]):\n",
        "        translation = skimage.transform.AffineTransform(translation=(p[0], p[1]))\n",
        "        img_trnsltd = skimage.transform.warp(img, translation, mode='edge', preserve_range=True).astype(np.uint8)\n",
        "        translated.append(img_trnsltd)\n",
        "        \n",
        "        if flip:\n",
        "          translated.append(np.flipud(img_trnsltd))\n",
        "\n",
        "  return translated\n",
        "\n",
        "# scale & crop\n",
        "def create_scaled(img):\n",
        "  \n",
        "  scaled = []\n",
        "\n",
        "  # choose a 'soft' scaling factor \n",
        "  scale_factor = 1.3\n",
        "\n",
        "  # scale image\n",
        "  img_scaled = skimage.transform.rescale(\n",
        "      img, \n",
        "      scale = scale_factor, \n",
        "      anti_aliasing = True, \n",
        "      multichannel = True,\n",
        "      preserve_range = True).astype(np.uint8)\n",
        "  # print(\"scale change (%d, %d) : (%d, %d)\" % (img.shape[1], img.shape[0], img_scaled.shape[1], img_scaled.shape[0]))\n",
        "\n",
        "  # crop at the center and append to output list\n",
        "  crop_x = int(np.floor((img_scaled.shape[0] - img.shape[0]) / 2))\n",
        "  crop_y = int(np.floor((img_scaled.shape[1] - img.shape[1]) / 2))\n",
        "  # print(\"cropping point : (%d, %d)\" % (crop_x, crop_y))\n",
        "\n",
        "  scaled.append(img_scaled[crop_y:(crop_y + img.shape[1]), crop_x:(crop_x + img.shape[0]), :])\n",
        "  scaled.append(np.fliplr(img_scaled[crop_y:(crop_y + img.shape[1]), crop_x:(crop_x + img.shape[0]), :]))\n",
        "  # print(\"scaled & cropped : (%d, %d)\" % (img_scaled_cropped.shape[0], img_scaled_cropped.shape[1]))\n",
        "\n",
        "  # create scaled & cropped at {flipped, non-flipped} * {N, S, W, E, NE, SE, SW, NW}\n",
        "  crop_x_list = [ round(( random.random() * k + 1 ) * crop_x ) for k in [ 1.0, 1.0, -1.0, -1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0 ] ]\n",
        "  crop_y_list = [ round(( random.random() * k + 1 ) * crop_y ) for k in [ 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, -1.0, -1.0, 1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, 1.0 ] ]\n",
        "\n",
        "  for i, crop in enumerate([(x, y) for x, y in zip(crop_x_list, crop_y_list)]):\n",
        "    if (i % 2):\n",
        "      scaled.append(np.fliplr(img_scaled[crop[1]:(crop[1] + img.shape[1]), crop[0]:(crop[0] + img.shape[0]), :]))\n",
        "    else:\n",
        "      scaled.append(img_scaled[crop[1]:(crop[1] + img.shape[1]), crop[0]:(crop[0] + img.shape[0]), :])\n",
        "\n",
        "  return scaled\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02AFqgMJ0nct"
      },
      "source": [
        "# testing area\n",
        "\n",
        "img = PIL.Image.open(os.path.join(DATASET_PATH, 'resistor/001.png'))\n",
        "img = np.asarray(img)\n",
        "\n",
        "# create simple array of translated images\n",
        "translated = create_translated(img, translation_coef = [1.0], flip = False)\n",
        "figs, axs = plt.subplots(1, len(translated), figsize=(30, 30))\n",
        "\n",
        "for i in range(len(translated)):\n",
        "  axs[i].imshow(translated[i], vmin=0, vmax=255)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# create array of rotated images\n",
        "rotated = create_rotated(img, angles = [-45, -22.5, -11.25, 11.25, 22.5, 45])\n",
        "figs, axs = plt.subplots(1, len(rotated) + 1, figsize=(30, 30))\n",
        "axs[0].imshow(img, vmin=0, vmax=255)\n",
        "for i in range(len(rotated)):\n",
        "  axs[i + 1].imshow(rotated[i], vmin=0, vmax=255)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# create array of rotations, applied over translations\n",
        "for img_trnslt in create_translated(img, translation_coef = [0.0, .25, .5]):\n",
        "  trans_rotated = create_rotated(img_trnslt, angles = [-11.25, 11.25])\n",
        "  figs, axs = plt.subplots(1, len(trans_rotated) + 1, figsize=(30, 30))\n",
        "  axs[0].imshow(img, vmin=0, vmax=255)\n",
        "  for i in range(len(trans_rotated)):\n",
        "    axs[i + 1].imshow(trans_rotated[i], vmin=0, vmax=255)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "# scaled = create_scaled(img)\n",
        "# figs, axs = plt.subplots(1, len(scaled), figsize=(30, 30))\n",
        "# for i in range(len(scaled)):\n",
        "#   axs[i].imshow(scaled[i], vmin=0, vmax=255)\n",
        "\n",
        "# plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaJR7hAOCEID"
      },
      "source": [
        "## Perform Transforms\n",
        "\n",
        "Call your functions to create a set of augmented data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ryKQeQaOKE"
      },
      "source": [
        "### Function to open image and create a list of new transforms\n",
        "# NOTE: You will need to call your functions here!\n",
        "def create_transforms(file_path):\n",
        "\n",
        "  # Open the image\n",
        "  img = PIL.Image.open(file_path)\n",
        "\n",
        "  # Convert the image to a Numpy array (keep all color channels)\n",
        "  img_array = np.asarray(img)\n",
        "\n",
        "  # Add original image to front of list\n",
        "  img_tfs = []\n",
        "  img_tfs.append([img_array])\n",
        "\n",
        "  # Perform transforms (call your functions)\n",
        "  # img_tfs.append(create_flipped(img_array))\n",
        "  # >>> ENTER YOUR CODE HERE <<<\n",
        "  # e.g. img_tfs.append(create_translations(img_array, 2))\n",
        "\n",
        "  # add translations with coefficients [.0, .25, .5, .75]\n",
        "  img_tfs.append(create_translated(img_array, translation_coef = [.0, .25, .5, .75], flip = True))\n",
        "  # add rotations with angles [-22.5, -11.25, 11.25, 22.5] and translation coefficients [.0, .25]\n",
        "  # for img_trnslt in create_translated(img_array, translation_coef = [.0, .25]):\n",
        "  #   img_tfs.append(create_rotated(img_trnslt, angles = [-22.5, -11.25, 11.25, 22.5], flip = True))\n",
        "\n",
        "  # Flatten list of lists (to create one long list of images)\n",
        "  img_tfs = [img for img_list in img_tfs for img in img_list]\n",
        "\n",
        "  return img_tfs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3ZEsAGUAvUS"
      },
      "source": [
        "### Load all images, create transforms, and save in output directory\n",
        "\n",
        "# Find the directories in the dataset folder (skip the Jupyter Notebook checkpoints hidden folder)\n",
        "for label in os.listdir(DATASET_PATH):\n",
        "  class_dir = os.path.join(DATASET_PATH, label)\n",
        "  if os.path.isdir(class_dir) and label != \".ipynb_checkpoints\":\n",
        "\n",
        "    # Create output directory\n",
        "    out_path = os.path.join(OUT_PATH, label)\n",
        "    os.makedirs(out_path, exist_ok=True)\n",
        "\n",
        "    # Go through each image in the subfolder\n",
        "    for i, filename in enumerate(os.listdir(class_dir)):\n",
        "\n",
        "      # Skip the Jupyter Notebook checkpoints folder that sometimes gets added\n",
        "      if filename != \".ipynb_checkpoints\":\n",
        "\n",
        "        # Get the root of the filename before the extension\n",
        "        file_root = os.path.splitext(filename)[0]\n",
        "\n",
        "        # Do all transforms for that one image\n",
        "        file_path = os.path.join(DATASET_PATH, label, filename)\n",
        "        img_tfs = create_transforms(file_path)\n",
        "\n",
        "        # Save images to new files in output directory\n",
        "        for i, img in enumerate(img_tfs):\n",
        "\n",
        "          # Create a Pillow image from the Numpy array\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "\n",
        "          # Construct filename (<orignal>_<transform_num>.<EXT>)\n",
        "          out_file_path = os.path.join(out_path, file_root + \"_\" + str(i) + IMG_EXT)\n",
        "\n",
        "          # Convert Numpy array to image and save as a file\n",
        "          img_pil = PIL.Image.fromarray(img)\n",
        "          img_pil.save(out_file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWwxvzKxDJ18"
      },
      "source": [
        "### Zip our new dataset (use '!' to call Linux commands)\n",
        "!zip -r -q \"{OUT_ZIP}\" \"{OUT_PATH}\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS_SETYgSIaz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}